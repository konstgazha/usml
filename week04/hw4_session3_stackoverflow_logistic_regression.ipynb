{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "Автор материала: Павел Нестеров (@mephistopheies). Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.1\n",
      "IPython 5.3.0\n",
      "\n",
      "numpy 1.12.1\n",
      "scipy 0.19.0\n",
      "pandas 0.20.1\n",
      "matplotlib 2.0.2\n",
      "sklearn 0.18.1\n",
      "\n",
      "compiler   : MSC v.1900 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 10\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 60 Stepping 3, GenuineIntel\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   :\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = 'D:\\\\usml\\\\mlcourse_open\\\\jupyter_russian\\\\homeworks\\\\stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = 'D:\\\\usml\\\\mlcourse_open\\\\jupyter_russian\\\\homeworks\\\\top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c++', 'ios', 'python', 'php', 'jquery', 'android', 'html', 'c#', 'javascript', 'java'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} \\\\\n",
    "&=& \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\vec{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\vec{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} \\\\\n",
    "&=& \\sigma_k\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\vec{x}}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\vec{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\vec{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\vec{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\begin{array}{rcl}\n",
    "\\large - \\mathcal{L} = \\large - \\log p\\left({\\vec{x}}\\right) &=& \\large - \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font>В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    if z >= 0:\n",
    "                        sigma = 1 / (1 + np.exp(-z))\n",
    "                    else:\n",
    "                        sigma = 1 - 1 / (1 + np.exp(-z))\n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    if sigma > tolerance:\n",
    "                        sample_loss += -y * np.log(sigma)\n",
    "                    else:\n",
    "                        sample_loss += -y * np.log(tolerance)\n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83889340157f48d2a7fec3768d6f0212"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA50AAAKqCAYAAAC5JDrrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x246c2d5f240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 10.95\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. 19.74\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. 0.59\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.59\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. c# \n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. ios\n",
    "3. php\n",
    "4. java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
