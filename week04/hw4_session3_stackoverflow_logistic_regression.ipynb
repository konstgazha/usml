{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "Автор материала: Павел Нестеров (@mephistopheies). Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.1\n",
      "IPython 5.3.0\n",
      "\n",
      "numpy 1.12.1\n",
      "scipy 0.19.0\n",
      "pandas 0.20.1\n",
      "matplotlib 2.0.2\n",
      "sklearn 0.18.1\n",
      "\n",
      "compiler   : MSC v.1900 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 10\n",
      "machine    : AMD64\n",
      "processor  : Intel64 Family 6 Model 60 Stepping 3, GenuineIntel\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   :\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = 'D:\\\\usml\\\\mlcourse_open\\\\jupyter_russian\\\\homeworks\\\\stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = 'D:\\\\usml\\\\mlcourse_open\\\\jupyter_russian\\\\homeworks\\\\top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c++', 'ios', 'python', 'php', 'jquery', 'android', 'html', 'c#', 'javascript', 'java'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} \\\\\n",
    "&=& \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\vec{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\vec{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} \\\\\n",
    "&=& \\sigma_k\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\vec{x}}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\vec{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\vec{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\vec{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\begin{array}{rcl}\n",
    "\\large - \\mathcal{L} = \\large - \\log p\\left({\\vec{x}}\\right) &=& \\large - \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \n",
    "\\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font>В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    if z >= 0:\n",
    "                        sigma = 1 / (1 + np.exp(-z))\n",
    "                    else:\n",
    "                        sigma = 1 - 1 / (1 + np.exp(z))\n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    if y == 1:\n",
    "                        if sigma > tolerance:\n",
    "                            sample_loss += -y * np.log(sigma)\n",
    "                        else:\n",
    "                            sample_loss += -y * np.log(tolerance)\n",
    "                    else:\n",
    "                        if sigma < 1 - tolerance:\n",
    "                            sample_loss += -(1 - y) * np.log(1 - sigma)\n",
    "                        else:\n",
    "                            sample_loss += -(1 - y) * np.log(1 - (1 - tolerance))\n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f22bf2a884e445198efc6ba8b8b191e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA50AAAKqCAYAAAC5JDrrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCQAAAAAwzf8DDs0B7hN5vNsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x246dad26e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 20.04\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. 19.74\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. 0.59\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. 0.52"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.59\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. c# \n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. ios\n",
    "3. php\n",
    "4. java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
